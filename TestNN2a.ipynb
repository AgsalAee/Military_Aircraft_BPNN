{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy_0</th>\n",
       "      <th>homogenity_0</th>\n",
       "      <th>entrophy_0</th>\n",
       "      <th>contrast_0</th>\n",
       "      <th>energy_45</th>\n",
       "      <th>homogenity_45</th>\n",
       "      <th>entrophy_45</th>\n",
       "      <th>contrast_45</th>\n",
       "      <th>energy_90</th>\n",
       "      <th>homogenity_90</th>\n",
       "      <th>...</th>\n",
       "      <th>energy_135</th>\n",
       "      <th>homogenity_135</th>\n",
       "      <th>entrophy_135</th>\n",
       "      <th>contrast_135</th>\n",
       "      <th>fusi_energy</th>\n",
       "      <th>fusi_homogenity</th>\n",
       "      <th>fusi_entrophy</th>\n",
       "      <th>fusi_contrast</th>\n",
       "      <th>kelas</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.240005</td>\n",
       "      <td>331.516238</td>\n",
       "      <td>4.742113</td>\n",
       "      <td>330.516238</td>\n",
       "      <td>0.231082</td>\n",
       "      <td>818.749884</td>\n",
       "      <td>4.973207</td>\n",
       "      <td>817.749884</td>\n",
       "      <td>0.236720</td>\n",
       "      <td>545.250246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231363</td>\n",
       "      <td>645.163841</td>\n",
       "      <td>4.930189</td>\n",
       "      <td>644.163841</td>\n",
       "      <td>0.939170</td>\n",
       "      <td>2340.680209</td>\n",
       "      <td>19.511409</td>\n",
       "      <td>2336.680209</td>\n",
       "      <td>fighter</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.239120</td>\n",
       "      <td>331.866391</td>\n",
       "      <td>4.726771</td>\n",
       "      <td>330.866391</td>\n",
       "      <td>0.230489</td>\n",
       "      <td>646.219577</td>\n",
       "      <td>4.904769</td>\n",
       "      <td>645.219577</td>\n",
       "      <td>0.234241</td>\n",
       "      <td>546.284172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230034</td>\n",
       "      <td>819.911965</td>\n",
       "      <td>4.948246</td>\n",
       "      <td>818.911965</td>\n",
       "      <td>0.933884</td>\n",
       "      <td>2344.282105</td>\n",
       "      <td>19.432075</td>\n",
       "      <td>2340.282105</td>\n",
       "      <td>fighter</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.497151</td>\n",
       "      <td>258.925613</td>\n",
       "      <td>2.885148</td>\n",
       "      <td>257.925613</td>\n",
       "      <td>0.494105</td>\n",
       "      <td>423.701868</td>\n",
       "      <td>2.968974</td>\n",
       "      <td>422.701868</td>\n",
       "      <td>0.495796</td>\n",
       "      <td>329.489604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494588</td>\n",
       "      <td>387.862004</td>\n",
       "      <td>2.941243</td>\n",
       "      <td>386.862004</td>\n",
       "      <td>1.981640</td>\n",
       "      <td>1399.979089</td>\n",
       "      <td>11.684273</td>\n",
       "      <td>1395.979089</td>\n",
       "      <td>fighter</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.497625</td>\n",
       "      <td>258.919608</td>\n",
       "      <td>2.881818</td>\n",
       "      <td>257.919608</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>387.868396</td>\n",
       "      <td>2.938185</td>\n",
       "      <td>386.868396</td>\n",
       "      <td>0.496315</td>\n",
       "      <td>329.510611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494755</td>\n",
       "      <td>423.740250</td>\n",
       "      <td>2.965840</td>\n",
       "      <td>422.740250</td>\n",
       "      <td>1.983933</td>\n",
       "      <td>1400.038865</td>\n",
       "      <td>11.671823</td>\n",
       "      <td>1396.038865</td>\n",
       "      <td>fighter</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.355096</td>\n",
       "      <td>553.787439</td>\n",
       "      <td>3.759853</td>\n",
       "      <td>552.787439</td>\n",
       "      <td>0.340568</td>\n",
       "      <td>1170.322094</td>\n",
       "      <td>3.933239</td>\n",
       "      <td>1169.322094</td>\n",
       "      <td>0.347928</td>\n",
       "      <td>871.335445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340877</td>\n",
       "      <td>1065.101096</td>\n",
       "      <td>3.899414</td>\n",
       "      <td>1064.101096</td>\n",
       "      <td>1.384469</td>\n",
       "      <td>3660.546074</td>\n",
       "      <td>15.420127</td>\n",
       "      <td>3656.546074</td>\n",
       "      <td>fighter</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   energy_0  homogenity_0  entrophy_0  contrast_0  energy_45  homogenity_45  \\\n",
       "0  0.240005    331.516238    4.742113  330.516238   0.231082     818.749884   \n",
       "1  0.239120    331.866391    4.726771  330.866391   0.230489     646.219577   \n",
       "2  0.497151    258.925613    2.885148  257.925613   0.494105     423.701868   \n",
       "3  0.497625    258.919608    2.881818  257.919608   0.495238     387.868396   \n",
       "4  0.355096    553.787439    3.759853  552.787439   0.340568    1170.322094   \n",
       "\n",
       "   entrophy_45  contrast_45  energy_90  homogenity_90  ...  energy_135  \\\n",
       "0     4.973207   817.749884   0.236720     545.250246  ...    0.231363   \n",
       "1     4.904769   645.219577   0.234241     546.284172  ...    0.230034   \n",
       "2     2.968974   422.701868   0.495796     329.489604  ...    0.494588   \n",
       "3     2.938185   386.868396   0.496315     329.510611  ...    0.494755   \n",
       "4     3.933239  1169.322094   0.347928     871.335445  ...    0.340877   \n",
       "\n",
       "   homogenity_135  entrophy_135  contrast_135  fusi_energy  fusi_homogenity  \\\n",
       "0      645.163841      4.930189    644.163841     0.939170      2340.680209   \n",
       "1      819.911965      4.948246    818.911965     0.933884      2344.282105   \n",
       "2      387.862004      2.941243    386.862004     1.981640      1399.979089   \n",
       "3      423.740250      2.965840    422.740250     1.983933      1400.038865   \n",
       "4     1065.101096      3.899414   1064.101096     1.384469      3660.546074   \n",
       "\n",
       "   fusi_entrophy  fusi_contrast    kelas  Unnamed: 22  \n",
       "0      19.511409    2336.680209  fighter          NaN  \n",
       "1      19.432075    2340.282105  fighter          NaN  \n",
       "2      11.684273    1395.979089  fighter          NaN  \n",
       "3      11.671823    1396.038865  fighter          NaN  \n",
       "4      15.420127    3656.546074  fighter          NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "# import seaborn as sns\n",
    "df = pd.read_excel('WarnaFlipNonFlipFusi.xlsx')\n",
    "# df.drop(['file','energy_0','homogenity_0','entrophy_0','contrast_0','energy_45','homogenity_45','entrophy_45','contrast_45','energy_90','homogenity_90','entrophy_90','contrast_90','energy_135','homogenity_135','entrophy_135','contrast_135'],axis=1, inplace=True)\n",
    "df.drop('file', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fusi_energy</th>\n",
       "      <th>fusi_homogenity</th>\n",
       "      <th>fusi_entrophy</th>\n",
       "      <th>fusi_contrast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.939170</td>\n",
       "      <td>2340.680209</td>\n",
       "      <td>19.511409</td>\n",
       "      <td>2336.680209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.933884</td>\n",
       "      <td>2344.282105</td>\n",
       "      <td>19.432075</td>\n",
       "      <td>2340.282105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.981640</td>\n",
       "      <td>1399.979089</td>\n",
       "      <td>11.684273</td>\n",
       "      <td>1395.979089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.983933</td>\n",
       "      <td>1400.038865</td>\n",
       "      <td>11.671823</td>\n",
       "      <td>1396.038865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.384469</td>\n",
       "      <td>3660.546074</td>\n",
       "      <td>15.420127</td>\n",
       "      <td>3656.546074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>1.801781</td>\n",
       "      <td>2942.099942</td>\n",
       "      <td>13.508116</td>\n",
       "      <td>2938.099942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>1.832663</td>\n",
       "      <td>2124.943591</td>\n",
       "      <td>13.020960</td>\n",
       "      <td>2120.943591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>1.814780</td>\n",
       "      <td>2125.250680</td>\n",
       "      <td>13.084556</td>\n",
       "      <td>2121.250680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>1.471923</td>\n",
       "      <td>3858.694772</td>\n",
       "      <td>16.240382</td>\n",
       "      <td>3854.694772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>1.475054</td>\n",
       "      <td>3859.098589</td>\n",
       "      <td>16.222360</td>\n",
       "      <td>3855.098589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fusi_energy  fusi_homogenity  fusi_entrophy  fusi_contrast\n",
       "0        0.939170      2340.680209      19.511409    2336.680209\n",
       "1        0.933884      2344.282105      19.432075    2340.282105\n",
       "2        1.981640      1399.979089      11.684273    1395.979089\n",
       "3        1.983933      1400.038865      11.671823    1396.038865\n",
       "4        1.384469      3660.546074      15.420127    3656.546074\n",
       "...           ...              ...            ...            ...\n",
       "2043     1.801781      2942.099942      13.508116    2938.099942\n",
       "2044     1.832663      2124.943591      13.020960    2120.943591\n",
       "2045     1.814780      2125.250680      13.084556    2121.250680\n",
       "2046     1.471923      3858.694772      16.240382    3854.694772\n",
       "2047     1.475054      3859.098589      16.222360    3855.098589\n",
       "\n",
       "[2048 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "# label_encoder = preprocessing.LabelEncoder()\n",
    "# df['kelas'] = label_encoder.fit_transform(df['kelas'])\n",
    "\n",
    "## split target and data \n",
    "# properties = list(df.columns.values)\n",
    "# properties.remove('kelas')\n",
    "# print(properties)\n",
    "# X = df[properties]\n",
    "# y = df['kelas']\n",
    "\n",
    "## split target and data\n",
    "# X = df.iloc[:,:-1]\n",
    "y = df.loc[:, lambda df:['kelas']]\n",
    "\n",
    "## split target and data\n",
    "# feature_cols = [\"energy_0\",\"homogenity_0\",\"entrophy_0\",\"contrast_0\"\n",
    "#                 ,\"energy_45\",\"homogenity_45\",\"entrophy_45\",\"contrast_45\"\n",
    "#                 ,\"energy_90\",\"homogenity_90\",\"entrophy_90\",\"contrast_90\"\n",
    "#                 ,\"energy_135\",\"homogenity_135\",\"entrophy_135\",\"contrast_135\"\n",
    "#                 ,\"fusi_energy\",\"fusi_homogenity\",\"fusi_entrophy\",\"fusi_contrast\"]\n",
    "feature_cols = [\"fusi_energy\",\"fusi_homogenity\",\"fusi_entrophy\",\"fusi_contrast\"]\n",
    "\n",
    "X = df[feature_cols]\n",
    "# y = df.kelas\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kelas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fighter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fighter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fighter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fighter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fighter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>attacker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2048 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         kelas\n",
       "0      fighter\n",
       "1      fighter\n",
       "2      fighter\n",
       "3      fighter\n",
       "4      fighter\n",
       "...        ...\n",
       "2043  attacker\n",
       "2044  attacker\n",
       "2045  attacker\n",
       "2046  attacker\n",
       "2047  attacker\n",
       "\n",
       "[2048 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fighter     1090\n",
       "attacker     958\n",
       "Name: kelas, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[\"kelas\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup_kelas = {\"kelas\" :{\"attacker\":0, \"fighter\"=1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # seperti 1 hot, direplace menjadi 1 kelas\n",
    "# y[\"kelas\"] = np.where(y[\"kelas\"].str.contains(\"fighter\"), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(y.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# oe_style = OneHotEncoder()\n",
    "# oe_results = oe_style.fit_transform(y[[\"kelas\"]])\n",
    "# pd.DataFrame(oe_results.toarray(), columns=oe_style.categories_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standartscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# StdScaler = MinMaxScaler(feature_range=(-1,1))\n",
    "StdScaler = StandardScaler()\n",
    "StdScaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# names = X.columns\n",
    "# X_tr, X_ts, X_vl = scaler.fit_transform(X_train), scaler.fit_transform(X_test), scaler.fit_transform(X_val)\n",
    "# X_train, X_test, X_val = pd.DataFrame(X_tr, columns=names), pd.DataFrame(X_ts, columns=names), pd.DataFrame(X_vl, columns=names)\n",
    "# X_train\n",
    "X_train1 = StdScaler.transform(X_train).min(axis=0)\n",
    "X_train2 = StdScaler.transform(X_train).max(axis=0)\n",
    "X_train3 = StdScaler.transform(X_train).mean(axis=0)\n",
    "X_train4 = StdScaler.transform(X_train).std(axis=0)\n",
    "X_train = StdScaler.transform(X_train)\n",
    "\n",
    "\n",
    "X_test = StdScaler.transform(X_test)\n",
    "# X_val = StdScaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.91300868, -1.63593725, -3.40796529, -1.63593725])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.0558829 , 4.31481139, 3.13009328, 4.31481139])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.95288198e-16, -2.79250236e-16, -3.90408097e-17,  6.50680161e-17])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing nilai murni tidak pakai standart scaler\n",
    "# #sekarang pake stdscl\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "names = X.columns\n",
    "# X_tr, X_ts, X_vl = scaler.fit_transform(X_train), scaler.fit_transform(X_test), scaler.fit_transform(X_val)\n",
    "X_train, X_test = pd.DataFrame(X_train, columns=names), pd.DataFrame(X_test, columns=names)\n",
    "# # X_train\n",
    "\n",
    "# # print(X_train['fusi_energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fusi_energy</th>\n",
       "      <th>fusi_homogenity</th>\n",
       "      <th>fusi_entrophy</th>\n",
       "      <th>fusi_contrast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.299754</td>\n",
       "      <td>0.311370</td>\n",
       "      <td>0.716036</td>\n",
       "      <td>0.311370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.173954</td>\n",
       "      <td>-0.454333</td>\n",
       "      <td>0.217408</td>\n",
       "      <td>-0.454333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.334228</td>\n",
       "      <td>1.864018</td>\n",
       "      <td>1.180889</td>\n",
       "      <td>1.864018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956148</td>\n",
       "      <td>0.135050</td>\n",
       "      <td>-0.881339</td>\n",
       "      <td>0.135050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.806891</td>\n",
       "      <td>4.314811</td>\n",
       "      <td>1.931746</td>\n",
       "      <td>4.314811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>-0.738231</td>\n",
       "      <td>0.622834</td>\n",
       "      <td>0.843801</td>\n",
       "      <td>0.622834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1.190851</td>\n",
       "      <td>-1.217124</td>\n",
       "      <td>-1.422815</td>\n",
       "      <td>-1.217124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>0.877176</td>\n",
       "      <td>-0.351207</td>\n",
       "      <td>-0.529882</td>\n",
       "      <td>-0.351207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>-0.170739</td>\n",
       "      <td>0.179048</td>\n",
       "      <td>0.328410</td>\n",
       "      <td>0.179048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.521756</td>\n",
       "      <td>0.038973</td>\n",
       "      <td>0.521756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1638 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fusi_energy  fusi_homogenity  fusi_entrophy  fusi_contrast\n",
       "0       -0.299754         0.311370       0.716036       0.311370\n",
       "1       -0.173954        -0.454333       0.217408      -0.454333\n",
       "2       -1.334228         1.864018       1.180889       1.864018\n",
       "3        0.956148         0.135050      -0.881339       0.135050\n",
       "4       -1.806891         4.314811       1.931746       4.314811\n",
       "...           ...              ...            ...            ...\n",
       "1633    -0.738231         0.622834       0.843801       0.622834\n",
       "1634     1.190851        -1.217124      -1.422815      -1.217124\n",
       "1635     0.877176        -0.351207      -0.529882      -0.351207\n",
       "1636    -0.170739         0.179048       0.328410       0.179048\n",
       "1637     0.006823         0.521756       0.038973       0.521756\n",
       "\n",
       "[1638 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kelas   \n",
       "fighter     872\n",
       "attacker    766\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kelas   \n",
       "attacker    872\n",
       "fighter     872\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to multiclass target\n",
    "y_train_enc, y_test_enc = pd.get_dummies(y_train_res), pd.get_dummies(y_test)\n",
    "# y_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fusi_energy</th>\n",
       "      <th>fusi_homogenity</th>\n",
       "      <th>fusi_entrophy</th>\n",
       "      <th>fusi_contrast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.299754</td>\n",
       "      <td>0.311370</td>\n",
       "      <td>0.716036</td>\n",
       "      <td>0.311370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.173954</td>\n",
       "      <td>-0.454333</td>\n",
       "      <td>0.217408</td>\n",
       "      <td>-0.454333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.334228</td>\n",
       "      <td>1.864018</td>\n",
       "      <td>1.180889</td>\n",
       "      <td>1.864018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956148</td>\n",
       "      <td>0.135050</td>\n",
       "      <td>-0.881339</td>\n",
       "      <td>0.135050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.806891</td>\n",
       "      <td>4.314811</td>\n",
       "      <td>1.931746</td>\n",
       "      <td>4.314811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>-0.738231</td>\n",
       "      <td>0.622834</td>\n",
       "      <td>0.843801</td>\n",
       "      <td>0.622834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1.190851</td>\n",
       "      <td>-1.217124</td>\n",
       "      <td>-1.422815</td>\n",
       "      <td>-1.217124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>0.877176</td>\n",
       "      <td>-0.351207</td>\n",
       "      <td>-0.529882</td>\n",
       "      <td>-0.351207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>-0.170739</td>\n",
       "      <td>0.179048</td>\n",
       "      <td>0.328410</td>\n",
       "      <td>0.179048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.521756</td>\n",
       "      <td>0.038973</td>\n",
       "      <td>0.521756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1638 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fusi_energy  fusi_homogenity  fusi_entrophy  fusi_contrast\n",
       "0       -0.299754         0.311370       0.716036       0.311370\n",
       "1       -0.173954        -0.454333       0.217408      -0.454333\n",
       "2       -1.334228         1.864018       1.180889       1.864018\n",
       "3        0.956148         0.135050      -0.881339       0.135050\n",
       "4       -1.806891         4.314811       1.931746       4.314811\n",
       "...           ...              ...            ...            ...\n",
       "1633    -0.738231         0.622834       0.843801       0.622834\n",
       "1634     1.190851        -1.217124      -1.422815      -1.217124\n",
       "1635     0.877176        -0.351207      -0.529882      -0.351207\n",
       "1636    -0.170739         0.179048       0.328410       0.179048\n",
       "1637     0.006823         0.521756       0.038973       0.521756\n",
       "\n",
       "[1638 rows x 4 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fusi_energy</th>\n",
       "      <th>fusi_homogenity</th>\n",
       "      <th>fusi_entrophy</th>\n",
       "      <th>fusi_contrast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.299754</td>\n",
       "      <td>0.311370</td>\n",
       "      <td>0.716036</td>\n",
       "      <td>0.311370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.173954</td>\n",
       "      <td>-0.454333</td>\n",
       "      <td>0.217408</td>\n",
       "      <td>-0.454333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.334228</td>\n",
       "      <td>1.864018</td>\n",
       "      <td>1.180889</td>\n",
       "      <td>1.864018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956148</td>\n",
       "      <td>0.135050</td>\n",
       "      <td>-0.881339</td>\n",
       "      <td>0.135050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.806891</td>\n",
       "      <td>4.314811</td>\n",
       "      <td>1.931746</td>\n",
       "      <td>4.314811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>-0.215889</td>\n",
       "      <td>-0.262252</td>\n",
       "      <td>0.430279</td>\n",
       "      <td>-0.262252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>-0.761711</td>\n",
       "      <td>-0.999912</td>\n",
       "      <td>0.325459</td>\n",
       "      <td>-0.999912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>-0.293512</td>\n",
       "      <td>0.985337</td>\n",
       "      <td>0.547661</td>\n",
       "      <td>0.985337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1.010788</td>\n",
       "      <td>-0.673425</td>\n",
       "      <td>-0.696847</td>\n",
       "      <td>-0.673425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>0.143130</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.318662</td>\n",
       "      <td>0.252405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fusi_energy  fusi_homogenity  fusi_entrophy  fusi_contrast\n",
       "0       -0.299754         0.311370       0.716036       0.311370\n",
       "1       -0.173954        -0.454333       0.217408      -0.454333\n",
       "2       -1.334228         1.864018       1.180889       1.864018\n",
       "3        0.956148         0.135050      -0.881339       0.135050\n",
       "4       -1.806891         4.314811       1.931746       4.314811\n",
       "...           ...              ...            ...            ...\n",
       "1739    -0.215889        -0.262252       0.430279      -0.262252\n",
       "1740    -0.761711        -0.999912       0.325459      -0.999912\n",
       "1741    -0.293512         0.985337       0.547661       0.985337\n",
       "1742     1.010788        -0.673425      -0.696847      -0.673425\n",
       "1743     0.143130         0.252405      -0.318662       0.252405\n",
       "\n",
       "[1744 rows x 4 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fusi_energy</th>\n",
       "      <th>fusi_homogenity</th>\n",
       "      <th>fusi_entrophy</th>\n",
       "      <th>fusi_contrast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.102136</td>\n",
       "      <td>-0.558720</td>\n",
       "      <td>-0.173665</td>\n",
       "      <td>-0.558720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.029469</td>\n",
       "      <td>1.646339</td>\n",
       "      <td>1.963668</td>\n",
       "      <td>1.646339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.855272</td>\n",
       "      <td>0.477538</td>\n",
       "      <td>1.187566</td>\n",
       "      <td>0.477538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.877403</td>\n",
       "      <td>-0.044028</td>\n",
       "      <td>2.024061</td>\n",
       "      <td>-0.044028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.323692</td>\n",
       "      <td>-0.875389</td>\n",
       "      <td>0.173394</td>\n",
       "      <td>-0.875389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1.283748</td>\n",
       "      <td>0.032576</td>\n",
       "      <td>-0.959957</td>\n",
       "      <td>0.032576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.022699</td>\n",
       "      <td>0.469231</td>\n",
       "      <td>0.075058</td>\n",
       "      <td>0.469231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.705398</td>\n",
       "      <td>-0.802158</td>\n",
       "      <td>-0.618734</td>\n",
       "      <td>-0.802158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.455148</td>\n",
       "      <td>-1.021590</td>\n",
       "      <td>-0.646230</td>\n",
       "      <td>-1.021590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.407643</td>\n",
       "      <td>-0.875039</td>\n",
       "      <td>0.019639</td>\n",
       "      <td>-0.875039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fusi_energy  fusi_homogenity  fusi_entrophy  fusi_contrast\n",
       "0      -0.102136        -0.558720      -0.173665      -0.558720\n",
       "1      -2.029469         1.646339       1.963668       1.646339\n",
       "2      -0.855272         0.477538       1.187566       0.477538\n",
       "3      -1.877403        -0.044028       2.024061      -0.044028\n",
       "4      -0.323692        -0.875389       0.173394      -0.875389\n",
       "..           ...              ...            ...            ...\n",
       "405     1.283748         0.032576      -0.959957       0.032576\n",
       "406     0.022699         0.469231       0.075058       0.469231\n",
       "407     0.705398        -0.802158      -0.618734      -0.802158\n",
       "408     0.455148        -1.021590      -0.646230      -1.021590\n",
       "409    -0.407643        -0.875039       0.019639      -0.875039\n",
       "\n",
       "[410 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=4, activation='relu', kernel_initializer='he_uniform',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=35)\n",
    "\n",
    "# opt = SGD(lr=0.4, momentum=0.9)\n",
    "# binarycr = tf.keras.losses.BinaryCrossentropy(\n",
    "#     from_logits=False,\n",
    "#     label_smoothing=0.0,\n",
    "#     axis=-1,\n",
    "#     reduction=\"auto\",\n",
    "#     name=\"binary_crossentropy\",\n",
    "# )\n",
    "# model.compile(loss=binarycr, optimizer=opt, metrics=['accuracy'])\n",
    "catcros = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0,\n",
    "    axis=-1,\n",
    "    reduction=\"auto\",\n",
    "    name=\"categorical_crossentropy\",\n",
    ")\n",
    "model.compile(loss=catcros, optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                320       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,178\n",
      "Trainable params: 42,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/555\n",
      "55/55 [==============================] - 1s 8ms/step - loss: 1.9498 - accuracy: 0.5969 - val_loss: 1.8674 - val_accuracy: 0.5805\n",
      "Epoch 2/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 1.7660 - accuracy: 0.6353 - val_loss: 1.7422 - val_accuracy: 0.5902\n",
      "Epoch 3/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 1.6381 - accuracy: 0.6456 - val_loss: 1.6046 - val_accuracy: 0.5927\n",
      "Epoch 4/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 1.5100 - accuracy: 0.6565 - val_loss: 1.5101 - val_accuracy: 0.5951\n",
      "Epoch 5/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 1.4160 - accuracy: 0.6634 - val_loss: 1.4049 - val_accuracy: 0.5951\n",
      "Epoch 6/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 1.3212 - accuracy: 0.6674 - val_loss: 1.3087 - val_accuracy: 0.6293\n",
      "Epoch 7/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 1.2375 - accuracy: 0.6737 - val_loss: 1.2385 - val_accuracy: 0.6073\n",
      "Epoch 8/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 1.1700 - accuracy: 0.6680 - val_loss: 1.1698 - val_accuracy: 0.6293\n",
      "Epoch 9/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 1.1131 - accuracy: 0.6869 - val_loss: 1.1107 - val_accuracy: 0.6317\n",
      "Epoch 10/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 1.0522 - accuracy: 0.6812 - val_loss: 1.0763 - val_accuracy: 0.6293\n",
      "Epoch 11/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 1.0081 - accuracy: 0.6835 - val_loss: 1.0238 - val_accuracy: 0.6317\n",
      "Epoch 12/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.9665 - accuracy: 0.6806 - val_loss: 0.9894 - val_accuracy: 0.6415\n",
      "Epoch 13/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.9249 - accuracy: 0.6846 - val_loss: 0.9645 - val_accuracy: 0.6317\n",
      "Epoch 14/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.8968 - accuracy: 0.6835 - val_loss: 0.9223 - val_accuracy: 0.6293\n",
      "Epoch 15/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.8617 - accuracy: 0.6961 - val_loss: 0.9006 - val_accuracy: 0.6366\n",
      "Epoch 16/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.8344 - accuracy: 0.6835 - val_loss: 0.8744 - val_accuracy: 0.6366\n",
      "Epoch 17/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.8132 - accuracy: 0.6944 - val_loss: 0.8512 - val_accuracy: 0.6512\n",
      "Epoch 18/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.7898 - accuracy: 0.7007 - val_loss: 0.8400 - val_accuracy: 0.6268\n",
      "Epoch 19/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.7663 - accuracy: 0.7007 - val_loss: 0.8326 - val_accuracy: 0.6268\n",
      "Epoch 20/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.7573 - accuracy: 0.7007 - val_loss: 0.8054 - val_accuracy: 0.6293\n",
      "Epoch 21/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.7047 - val_loss: 0.7805 - val_accuracy: 0.6512\n",
      "Epoch 22/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.7238 - accuracy: 0.6927 - val_loss: 0.7900 - val_accuracy: 0.6463\n",
      "Epoch 23/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.6984 - val_loss: 0.7519 - val_accuracy: 0.6512\n",
      "Epoch 24/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.7027 - accuracy: 0.7013 - val_loss: 0.7671 - val_accuracy: 0.6171\n",
      "Epoch 25/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.6978 - val_loss: 0.7460 - val_accuracy: 0.6415\n",
      "Epoch 26/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.7058 - val_loss: 0.7362 - val_accuracy: 0.6610\n",
      "Epoch 27/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7024 - val_loss: 0.7409 - val_accuracy: 0.6268\n",
      "Epoch 28/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.7058 - val_loss: 0.7331 - val_accuracy: 0.6512\n",
      "Epoch 29/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.7104 - val_loss: 0.7288 - val_accuracy: 0.6268\n",
      "Epoch 30/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.7093 - val_loss: 0.7210 - val_accuracy: 0.6488\n",
      "Epoch 31/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.7122 - val_loss: 0.7207 - val_accuracy: 0.6463\n",
      "Epoch 32/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.7116 - val_loss: 0.7067 - val_accuracy: 0.6683\n",
      "Epoch 33/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.7047 - val_loss: 0.7121 - val_accuracy: 0.6439\n",
      "Epoch 34/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.7087 - val_loss: 0.6977 - val_accuracy: 0.6537\n",
      "Epoch 35/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6984 - val_loss: 0.7181 - val_accuracy: 0.6463\n",
      "Epoch 36/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.7001 - val_loss: 0.6883 - val_accuracy: 0.6683\n",
      "Epoch 37/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.7122 - val_loss: 0.7024 - val_accuracy: 0.6390\n",
      "Epoch 38/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.7208 - val_loss: 0.7039 - val_accuracy: 0.6415\n",
      "Epoch 39/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.7236 - val_loss: 0.6931 - val_accuracy: 0.6634\n",
      "Epoch 40/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.7242 - val_loss: 0.7172 - val_accuracy: 0.6415\n",
      "Epoch 41/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7202 - val_loss: 0.7100 - val_accuracy: 0.6585\n",
      "Epoch 42/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7253 - val_loss: 0.6925 - val_accuracy: 0.6707\n",
      "Epoch 43/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.7242 - val_loss: 0.6723 - val_accuracy: 0.6585\n",
      "Epoch 44/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7362 - val_loss: 0.6916 - val_accuracy: 0.6488\n",
      "Epoch 45/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7460 - val_loss: 0.6878 - val_accuracy: 0.6537\n",
      "Epoch 46/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7351 - val_loss: 0.6820 - val_accuracy: 0.6585\n",
      "Epoch 47/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7408 - val_loss: 0.6921 - val_accuracy: 0.6683\n",
      "Epoch 48/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7271 - val_loss: 0.6738 - val_accuracy: 0.6561\n",
      "Epoch 49/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7466 - val_loss: 0.6974 - val_accuracy: 0.6732\n",
      "Epoch 50/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.7425 - val_loss: 0.6720 - val_accuracy: 0.6756\n",
      "Epoch 51/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7328 - val_loss: 0.6740 - val_accuracy: 0.6561\n",
      "Epoch 52/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7282 - val_loss: 0.6549 - val_accuracy: 0.6878\n",
      "Epoch 53/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7534 - val_loss: 0.6760 - val_accuracy: 0.6756\n",
      "Epoch 54/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7448 - val_loss: 0.6620 - val_accuracy: 0.6683\n",
      "Epoch 55/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7460 - val_loss: 0.6789 - val_accuracy: 0.6634\n",
      "Epoch 56/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7443 - val_loss: 0.6707 - val_accuracy: 0.6732\n",
      "Epoch 57/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7500 - val_loss: 0.6724 - val_accuracy: 0.6780\n",
      "Epoch 58/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7466 - val_loss: 0.6805 - val_accuracy: 0.6707\n",
      "Epoch 59/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7529 - val_loss: 0.6656 - val_accuracy: 0.6805\n",
      "Epoch 60/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7523 - val_loss: 0.6536 - val_accuracy: 0.6780\n",
      "Epoch 61/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7471 - val_loss: 0.6785 - val_accuracy: 0.6634\n",
      "Epoch 62/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7643 - val_loss: 0.6752 - val_accuracy: 0.6732\n",
      "Epoch 63/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7437 - val_loss: 0.6530 - val_accuracy: 0.6707\n",
      "Epoch 64/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7511 - val_loss: 0.6734 - val_accuracy: 0.6829\n",
      "Epoch 65/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7506 - val_loss: 0.6562 - val_accuracy: 0.6805\n",
      "Epoch 66/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7529 - val_loss: 0.6725 - val_accuracy: 0.6659\n",
      "Epoch 67/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7666 - val_loss: 0.6796 - val_accuracy: 0.6780\n",
      "Epoch 68/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7592 - val_loss: 0.6669 - val_accuracy: 0.6659\n",
      "Epoch 69/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7483 - val_loss: 0.6420 - val_accuracy: 0.6927\n",
      "Epoch 70/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7626 - val_loss: 0.6567 - val_accuracy: 0.6805\n",
      "Epoch 71/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7597 - val_loss: 0.6775 - val_accuracy: 0.6683\n",
      "Epoch 72/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7683 - val_loss: 0.6681 - val_accuracy: 0.6659\n",
      "Epoch 73/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7597 - val_loss: 0.6408 - val_accuracy: 0.6878\n",
      "Epoch 74/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7603 - val_loss: 0.6758 - val_accuracy: 0.6610\n",
      "Epoch 75/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7638 - val_loss: 0.6699 - val_accuracy: 0.6854\n",
      "Epoch 76/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7724 - val_loss: 0.6755 - val_accuracy: 0.6756\n",
      "Epoch 77/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7712 - val_loss: 0.6509 - val_accuracy: 0.6756\n",
      "Epoch 78/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7620 - val_loss: 0.6461 - val_accuracy: 0.6927\n",
      "Epoch 79/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7706 - val_loss: 0.6493 - val_accuracy: 0.6829\n",
      "Epoch 80/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7626 - val_loss: 0.6853 - val_accuracy: 0.6659\n",
      "Epoch 81/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7689 - val_loss: 0.6694 - val_accuracy: 0.6756\n",
      "Epoch 82/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7775 - val_loss: 0.6784 - val_accuracy: 0.6732\n",
      "Epoch 83/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7689 - val_loss: 0.6709 - val_accuracy: 0.6854\n",
      "Epoch 84/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7592 - val_loss: 0.6400 - val_accuracy: 0.7024\n",
      "Epoch 85/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7769 - val_loss: 0.6422 - val_accuracy: 0.6927\n",
      "Epoch 86/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7735 - val_loss: 0.6461 - val_accuracy: 0.6878\n",
      "Epoch 87/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7764 - val_loss: 0.6562 - val_accuracy: 0.7024\n",
      "Epoch 88/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7747 - val_loss: 0.6397 - val_accuracy: 0.6878\n",
      "Epoch 89/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7781 - val_loss: 0.6602 - val_accuracy: 0.6927\n",
      "Epoch 90/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7718 - val_loss: 0.6461 - val_accuracy: 0.6659\n",
      "Epoch 91/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7769 - val_loss: 0.6658 - val_accuracy: 0.6976\n",
      "Epoch 92/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7701 - val_loss: 0.6337 - val_accuracy: 0.6902\n",
      "Epoch 93/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7741 - val_loss: 0.6545 - val_accuracy: 0.6902\n",
      "Epoch 94/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7792 - val_loss: 0.6387 - val_accuracy: 0.6902\n",
      "Epoch 95/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7821 - val_loss: 0.6477 - val_accuracy: 0.7024\n",
      "Epoch 96/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7878 - val_loss: 0.6326 - val_accuracy: 0.7171\n",
      "Epoch 97/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7856 - val_loss: 0.6563 - val_accuracy: 0.7000\n",
      "Epoch 98/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7821 - val_loss: 0.6535 - val_accuracy: 0.7073\n",
      "Epoch 99/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7821 - val_loss: 0.6595 - val_accuracy: 0.6951\n",
      "Epoch 100/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7769 - val_loss: 0.6487 - val_accuracy: 0.6927\n",
      "Epoch 101/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7775 - val_loss: 0.6367 - val_accuracy: 0.6976\n",
      "Epoch 102/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7781 - val_loss: 0.6424 - val_accuracy: 0.6854\n",
      "Epoch 103/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7890 - val_loss: 0.6502 - val_accuracy: 0.7220\n",
      "Epoch 104/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7913 - val_loss: 0.6637 - val_accuracy: 0.7098\n",
      "Epoch 105/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7907 - val_loss: 0.6612 - val_accuracy: 0.7000\n",
      "Epoch 106/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7884 - val_loss: 0.6577 - val_accuracy: 0.6780\n",
      "Epoch 107/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7769 - val_loss: 0.6336 - val_accuracy: 0.7024\n",
      "Epoch 108/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7827 - val_loss: 0.6233 - val_accuracy: 0.7098\n",
      "Epoch 109/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7959 - val_loss: 0.6233 - val_accuracy: 0.7049\n",
      "Epoch 110/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7896 - val_loss: 0.6324 - val_accuracy: 0.7049\n",
      "Epoch 111/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7919 - val_loss: 0.6287 - val_accuracy: 0.6951\n",
      "Epoch 112/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7861 - val_loss: 0.6372 - val_accuracy: 0.7146\n",
      "Epoch 113/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7924 - val_loss: 0.6417 - val_accuracy: 0.7000\n",
      "Epoch 114/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7982 - val_loss: 0.6324 - val_accuracy: 0.7122\n",
      "Epoch 115/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7913 - val_loss: 0.6224 - val_accuracy: 0.7244\n",
      "Epoch 116/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7959 - val_loss: 0.6345 - val_accuracy: 0.7024\n",
      "Epoch 117/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7873 - val_loss: 0.6096 - val_accuracy: 0.7024\n",
      "Epoch 118/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7947 - val_loss: 0.6385 - val_accuracy: 0.7000\n",
      "Epoch 119/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7953 - val_loss: 0.6358 - val_accuracy: 0.7122\n",
      "Epoch 120/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7947 - val_loss: 0.6217 - val_accuracy: 0.7171\n",
      "Epoch 121/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7970 - val_loss: 0.6248 - val_accuracy: 0.7171\n",
      "Epoch 122/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8005 - val_loss: 0.6306 - val_accuracy: 0.7098\n",
      "Epoch 123/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7947 - val_loss: 0.6350 - val_accuracy: 0.7049\n",
      "Epoch 124/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7924 - val_loss: 0.6379 - val_accuracy: 0.7073\n",
      "Epoch 125/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7856 - val_loss: 0.6116 - val_accuracy: 0.7293\n",
      "Epoch 126/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7964 - val_loss: 0.6217 - val_accuracy: 0.7268\n",
      "Epoch 127/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7959 - val_loss: 0.6186 - val_accuracy: 0.7146\n",
      "Epoch 128/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.8050 - val_loss: 0.6577 - val_accuracy: 0.6927\n",
      "Epoch 129/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7959 - val_loss: 0.6237 - val_accuracy: 0.7244\n",
      "Epoch 130/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8039 - val_loss: 0.6056 - val_accuracy: 0.7244\n",
      "Epoch 131/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.8068 - val_loss: 0.6242 - val_accuracy: 0.7268\n",
      "Epoch 132/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.8039 - val_loss: 0.6137 - val_accuracy: 0.7293\n",
      "Epoch 133/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8016 - val_loss: 0.6274 - val_accuracy: 0.7098\n",
      "Epoch 134/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8045 - val_loss: 0.6137 - val_accuracy: 0.7171\n",
      "Epoch 135/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7924 - val_loss: 0.6259 - val_accuracy: 0.7171\n",
      "Epoch 136/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.8016 - val_loss: 0.6169 - val_accuracy: 0.7049\n",
      "Epoch 137/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.8033 - val_loss: 0.6159 - val_accuracy: 0.7073\n",
      "Epoch 138/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8050 - val_loss: 0.6199 - val_accuracy: 0.6976\n",
      "Epoch 139/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7919 - val_loss: 0.6184 - val_accuracy: 0.7268\n",
      "Epoch 140/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8010 - val_loss: 0.6036 - val_accuracy: 0.7439\n",
      "Epoch 141/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8091 - val_loss: 0.6418 - val_accuracy: 0.7268\n",
      "Epoch 142/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8194 - val_loss: 0.6150 - val_accuracy: 0.7415\n",
      "Epoch 143/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8033 - val_loss: 0.6038 - val_accuracy: 0.7366\n",
      "Epoch 144/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8085 - val_loss: 0.6009 - val_accuracy: 0.7146\n",
      "Epoch 145/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8119 - val_loss: 0.6100 - val_accuracy: 0.7244\n",
      "Epoch 146/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7959 - val_loss: 0.6280 - val_accuracy: 0.7024\n",
      "Epoch 147/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8171 - val_loss: 0.6262 - val_accuracy: 0.7341\n",
      "Epoch 148/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8068 - val_loss: 0.6006 - val_accuracy: 0.7195\n",
      "Epoch 149/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8200 - val_loss: 0.6057 - val_accuracy: 0.7171\n",
      "Epoch 150/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8062 - val_loss: 0.6158 - val_accuracy: 0.7268\n",
      "Epoch 151/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.8079 - val_loss: 0.5933 - val_accuracy: 0.7244\n",
      "Epoch 152/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.8119 - val_loss: 0.6366 - val_accuracy: 0.7073\n",
      "Epoch 153/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8136 - val_loss: 0.6508 - val_accuracy: 0.7122\n",
      "Epoch 154/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8171 - val_loss: 0.6372 - val_accuracy: 0.7171\n",
      "Epoch 155/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8142 - val_loss: 0.6292 - val_accuracy: 0.7293\n",
      "Epoch 156/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8194 - val_loss: 0.5982 - val_accuracy: 0.7244\n",
      "Epoch 157/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8131 - val_loss: 0.5985 - val_accuracy: 0.7341\n",
      "Epoch 158/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8188 - val_loss: 0.6189 - val_accuracy: 0.7317\n",
      "Epoch 159/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8211 - val_loss: 0.6244 - val_accuracy: 0.7195\n",
      "Epoch 160/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8171 - val_loss: 0.6139 - val_accuracy: 0.7317\n",
      "Epoch 161/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8171 - val_loss: 0.6161 - val_accuracy: 0.7366\n",
      "Epoch 162/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8222 - val_loss: 0.5921 - val_accuracy: 0.7415\n",
      "Epoch 163/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8217 - val_loss: 0.6263 - val_accuracy: 0.7122\n",
      "Epoch 164/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8159 - val_loss: 0.6079 - val_accuracy: 0.7293\n",
      "Epoch 165/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8171 - val_loss: 0.5813 - val_accuracy: 0.7390\n",
      "Epoch 166/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8142 - val_loss: 0.6222 - val_accuracy: 0.7293\n",
      "Epoch 167/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8263 - val_loss: 0.6108 - val_accuracy: 0.7366\n",
      "Epoch 168/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8320 - val_loss: 0.6187 - val_accuracy: 0.7415\n",
      "Epoch 169/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8177 - val_loss: 0.6059 - val_accuracy: 0.7293\n",
      "Epoch 170/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8171 - val_loss: 0.6285 - val_accuracy: 0.7268\n",
      "Epoch 171/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8159 - val_loss: 0.6290 - val_accuracy: 0.7341\n",
      "Epoch 172/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8188 - val_loss: 0.5648 - val_accuracy: 0.7488\n",
      "Epoch 173/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8245 - val_loss: 0.6218 - val_accuracy: 0.7098\n",
      "Epoch 174/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8188 - val_loss: 0.6011 - val_accuracy: 0.7610\n",
      "Epoch 175/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8165 - val_loss: 0.6169 - val_accuracy: 0.7366\n",
      "Epoch 176/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8125 - val_loss: 0.6014 - val_accuracy: 0.7293\n",
      "Epoch 177/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8188 - val_loss: 0.6293 - val_accuracy: 0.7317\n",
      "Epoch 178/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8211 - val_loss: 0.6373 - val_accuracy: 0.7293\n",
      "Epoch 179/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3994 - accuracy: 0.8263 - val_loss: 0.6205 - val_accuracy: 0.7439\n",
      "Epoch 180/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3929 - accuracy: 0.8222 - val_loss: 0.5954 - val_accuracy: 0.7463\n",
      "Epoch 181/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8205 - val_loss: 0.6285 - val_accuracy: 0.7195\n",
      "Epoch 182/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3996 - accuracy: 0.8177 - val_loss: 0.6203 - val_accuracy: 0.7415\n",
      "Epoch 183/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8200 - val_loss: 0.6735 - val_accuracy: 0.7024\n",
      "Epoch 184/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8182 - val_loss: 0.6049 - val_accuracy: 0.7634\n",
      "Epoch 185/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8228 - val_loss: 0.5861 - val_accuracy: 0.7415\n",
      "Epoch 186/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8228 - val_loss: 0.6488 - val_accuracy: 0.7317\n",
      "Epoch 187/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.8291 - val_loss: 0.5958 - val_accuracy: 0.7415\n",
      "Epoch 188/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8291 - val_loss: 0.6236 - val_accuracy: 0.7268\n",
      "Epoch 189/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8343 - val_loss: 0.6140 - val_accuracy: 0.7366\n",
      "Epoch 190/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8320 - val_loss: 0.6086 - val_accuracy: 0.7415\n",
      "Epoch 191/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8320 - val_loss: 0.6115 - val_accuracy: 0.7488\n",
      "Epoch 192/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8297 - val_loss: 0.5967 - val_accuracy: 0.7415\n",
      "Epoch 193/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8303 - val_loss: 0.6168 - val_accuracy: 0.7341\n",
      "Epoch 194/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8240 - val_loss: 0.5886 - val_accuracy: 0.7390\n",
      "Epoch 195/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3920 - accuracy: 0.8320 - val_loss: 0.5982 - val_accuracy: 0.7610\n",
      "Epoch 196/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8286 - val_loss: 0.6277 - val_accuracy: 0.7293\n",
      "Epoch 197/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8222 - val_loss: 0.6086 - val_accuracy: 0.7585\n",
      "Epoch 198/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3911 - accuracy: 0.8217 - val_loss: 0.5882 - val_accuracy: 0.7512\n",
      "Epoch 199/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8268 - val_loss: 0.6251 - val_accuracy: 0.7293\n",
      "Epoch 200/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8263 - val_loss: 0.6270 - val_accuracy: 0.7341\n",
      "Epoch 201/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8372 - val_loss: 0.6175 - val_accuracy: 0.7293\n",
      "Epoch 202/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8475 - val_loss: 0.6178 - val_accuracy: 0.7585\n",
      "Epoch 203/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8366 - val_loss: 0.5891 - val_accuracy: 0.7610\n",
      "Epoch 204/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8354 - val_loss: 0.6161 - val_accuracy: 0.7415\n",
      "Epoch 205/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8366 - val_loss: 0.6155 - val_accuracy: 0.7488\n",
      "Epoch 206/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8429 - val_loss: 0.6028 - val_accuracy: 0.7244\n",
      "Epoch 207/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8337 - val_loss: 0.5775 - val_accuracy: 0.7561\n",
      "Epoch 208/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8372 - val_loss: 0.6189 - val_accuracy: 0.7293\n",
      "Epoch 209/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8383 - val_loss: 0.5926 - val_accuracy: 0.7390\n",
      "Epoch 210/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8354 - val_loss: 0.6023 - val_accuracy: 0.7244\n",
      "Epoch 211/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8400 - val_loss: 0.5747 - val_accuracy: 0.7488\n",
      "Epoch 212/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8435 - val_loss: 0.5824 - val_accuracy: 0.7634\n",
      "Epoch 213/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8308 - val_loss: 0.5863 - val_accuracy: 0.7463\n",
      "Epoch 214/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8377 - val_loss: 0.6353 - val_accuracy: 0.7341\n",
      "Epoch 215/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8412 - val_loss: 0.6365 - val_accuracy: 0.7268\n",
      "Epoch 216/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8366 - val_loss: 0.6096 - val_accuracy: 0.7463\n",
      "Epoch 217/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8383 - val_loss: 0.6004 - val_accuracy: 0.7610\n",
      "Epoch 218/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8383 - val_loss: 0.6167 - val_accuracy: 0.7463\n",
      "Epoch 219/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8469 - val_loss: 0.6348 - val_accuracy: 0.7561\n",
      "Epoch 220/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8412 - val_loss: 0.6073 - val_accuracy: 0.7634\n",
      "Epoch 221/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8394 - val_loss: 0.6038 - val_accuracy: 0.7512\n",
      "Epoch 222/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8406 - val_loss: 0.6230 - val_accuracy: 0.7415\n",
      "Epoch 223/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.8389 - val_loss: 0.6250 - val_accuracy: 0.7366\n",
      "Epoch 224/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8366 - val_loss: 0.6101 - val_accuracy: 0.7415\n",
      "Epoch 225/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8486 - val_loss: 0.6098 - val_accuracy: 0.7634\n",
      "Epoch 226/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8400 - val_loss: 0.6121 - val_accuracy: 0.7659\n",
      "Epoch 227/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8429 - val_loss: 0.5991 - val_accuracy: 0.7585\n",
      "Epoch 228/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8452 - val_loss: 0.6200 - val_accuracy: 0.7512\n",
      "Epoch 229/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8486 - val_loss: 0.6047 - val_accuracy: 0.7463\n",
      "Epoch 230/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8377 - val_loss: 0.5999 - val_accuracy: 0.7683\n",
      "Epoch 231/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8463 - val_loss: 0.6439 - val_accuracy: 0.7366\n",
      "Epoch 232/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8481 - val_loss: 0.6238 - val_accuracy: 0.7415\n",
      "Epoch 233/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8423 - val_loss: 0.5903 - val_accuracy: 0.7561\n",
      "Epoch 234/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3578 - accuracy: 0.8481 - val_loss: 0.5936 - val_accuracy: 0.7561\n",
      "Epoch 235/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8383 - val_loss: 0.6007 - val_accuracy: 0.7634\n",
      "Epoch 236/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8544 - val_loss: 0.5900 - val_accuracy: 0.7634\n",
      "Epoch 237/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8452 - val_loss: 0.6131 - val_accuracy: 0.7659\n",
      "Epoch 238/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8366 - val_loss: 0.6285 - val_accuracy: 0.7537\n",
      "Epoch 239/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8544 - val_loss: 0.5977 - val_accuracy: 0.7634\n",
      "Epoch 240/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8624 - val_loss: 0.6074 - val_accuracy: 0.7585\n",
      "Epoch 241/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8624 - val_loss: 0.6058 - val_accuracy: 0.7756\n",
      "Epoch 242/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8526 - val_loss: 0.5801 - val_accuracy: 0.7829\n",
      "Epoch 243/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8526 - val_loss: 0.6218 - val_accuracy: 0.7659\n",
      "Epoch 244/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8653 - val_loss: 0.6134 - val_accuracy: 0.7463\n",
      "Epoch 245/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8544 - val_loss: 0.6454 - val_accuracy: 0.7683\n",
      "Epoch 246/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8601 - val_loss: 0.6233 - val_accuracy: 0.7415\n",
      "Epoch 247/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8532 - val_loss: 0.6330 - val_accuracy: 0.7463\n",
      "Epoch 248/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8354 - val_loss: 0.6105 - val_accuracy: 0.7488\n",
      "Epoch 249/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8492 - val_loss: 0.5898 - val_accuracy: 0.7683\n",
      "Epoch 250/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8503 - val_loss: 0.6029 - val_accuracy: 0.7634\n",
      "Epoch 251/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8589 - val_loss: 0.5566 - val_accuracy: 0.7927\n",
      "Epoch 252/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8303 - val_loss: 0.6369 - val_accuracy: 0.7561\n",
      "Epoch 253/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8538 - val_loss: 0.5686 - val_accuracy: 0.7707\n",
      "Epoch 254/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8584 - val_loss: 0.5913 - val_accuracy: 0.7927\n",
      "Epoch 255/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8515 - val_loss: 0.5755 - val_accuracy: 0.7756\n",
      "Epoch 256/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8469 - val_loss: 0.5939 - val_accuracy: 0.7439\n",
      "Epoch 257/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8526 - val_loss: 0.6009 - val_accuracy: 0.7878\n",
      "Epoch 258/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8612 - val_loss: 0.6007 - val_accuracy: 0.7756\n",
      "Epoch 259/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8584 - val_loss: 0.5929 - val_accuracy: 0.7659\n",
      "Epoch 260/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8561 - val_loss: 0.6046 - val_accuracy: 0.7683\n",
      "Epoch 261/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8458 - val_loss: 0.6177 - val_accuracy: 0.7366\n",
      "Epoch 262/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8612 - val_loss: 0.5916 - val_accuracy: 0.7683\n",
      "Epoch 263/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8515 - val_loss: 0.6368 - val_accuracy: 0.7634\n",
      "Epoch 264/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8578 - val_loss: 0.5899 - val_accuracy: 0.7927\n",
      "Epoch 265/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8561 - val_loss: 0.5625 - val_accuracy: 0.7902\n",
      "Epoch 266/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8532 - val_loss: 0.6203 - val_accuracy: 0.7707\n",
      "Epoch 267/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8607 - val_loss: 0.6212 - val_accuracy: 0.7634\n",
      "Epoch 268/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8624 - val_loss: 0.6269 - val_accuracy: 0.7561\n",
      "Epoch 269/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8567 - val_loss: 0.5983 - val_accuracy: 0.7488\n",
      "Epoch 270/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8561 - val_loss: 0.5780 - val_accuracy: 0.7976\n",
      "Epoch 271/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8664 - val_loss: 0.5960 - val_accuracy: 0.7610\n",
      "Epoch 272/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8555 - val_loss: 0.6006 - val_accuracy: 0.7976\n",
      "Epoch 273/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8630 - val_loss: 0.5884 - val_accuracy: 0.7707\n",
      "Epoch 274/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8675 - val_loss: 0.5996 - val_accuracy: 0.7927\n",
      "Epoch 275/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8492 - val_loss: 0.5896 - val_accuracy: 0.7488\n",
      "Epoch 276/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8647 - val_loss: 0.6043 - val_accuracy: 0.7732\n",
      "Epoch 277/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8572 - val_loss: 0.6041 - val_accuracy: 0.7902\n",
      "Epoch 278/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8486 - val_loss: 0.6363 - val_accuracy: 0.7585\n",
      "Epoch 279/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8681 - val_loss: 0.6040 - val_accuracy: 0.7732\n",
      "Epoch 280/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8675 - val_loss: 0.6414 - val_accuracy: 0.7293\n",
      "Epoch 281/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8675 - val_loss: 0.6622 - val_accuracy: 0.7512\n",
      "Epoch 282/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8733 - val_loss: 0.6077 - val_accuracy: 0.7951\n",
      "Epoch 283/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8664 - val_loss: 0.6334 - val_accuracy: 0.7634\n",
      "Epoch 284/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8658 - val_loss: 0.5847 - val_accuracy: 0.7805\n",
      "Epoch 285/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8733 - val_loss: 0.5937 - val_accuracy: 0.7463\n",
      "Epoch 286/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8630 - val_loss: 0.5779 - val_accuracy: 0.7659\n",
      "Epoch 287/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8721 - val_loss: 0.5878 - val_accuracy: 0.7902\n",
      "Epoch 288/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3148 - accuracy: 0.8767 - val_loss: 0.5725 - val_accuracy: 0.7878\n",
      "Epoch 289/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8526 - val_loss: 0.5889 - val_accuracy: 0.7732\n",
      "Epoch 290/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3187 - accuracy: 0.8710 - val_loss: 0.6078 - val_accuracy: 0.7805\n",
      "Epoch 291/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8572 - val_loss: 0.6287 - val_accuracy: 0.7707\n",
      "Epoch 292/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8618 - val_loss: 0.6259 - val_accuracy: 0.7659\n",
      "Epoch 293/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8698 - val_loss: 0.6144 - val_accuracy: 0.7878\n",
      "Epoch 294/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8767 - val_loss: 0.5845 - val_accuracy: 0.7732\n",
      "Epoch 295/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.8744 - val_loss: 0.6319 - val_accuracy: 0.7780\n",
      "Epoch 296/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8756 - val_loss: 0.6250 - val_accuracy: 0.7902\n",
      "Epoch 297/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.8664 - val_loss: 0.6004 - val_accuracy: 0.7683\n",
      "Epoch 298/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3086 - accuracy: 0.8813 - val_loss: 0.6241 - val_accuracy: 0.8049\n",
      "Epoch 299/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8761 - val_loss: 0.6041 - val_accuracy: 0.8049\n",
      "Epoch 300/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8716 - val_loss: 0.6217 - val_accuracy: 0.7902\n",
      "Epoch 301/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8733 - val_loss: 0.6144 - val_accuracy: 0.7683\n",
      "Epoch 302/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8658 - val_loss: 0.6225 - val_accuracy: 0.7780\n",
      "Epoch 303/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8624 - val_loss: 0.6134 - val_accuracy: 0.7805\n",
      "Epoch 304/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8710 - val_loss: 0.5696 - val_accuracy: 0.8171\n",
      "Epoch 305/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.8779 - val_loss: 0.6297 - val_accuracy: 0.7805\n",
      "Epoch 306/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8612 - val_loss: 0.5971 - val_accuracy: 0.8220\n",
      "Epoch 307/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8750 - val_loss: 0.6073 - val_accuracy: 0.7732\n",
      "Epoch 308/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3047 - accuracy: 0.8796 - val_loss: 0.6006 - val_accuracy: 0.7951\n",
      "Epoch 309/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8721 - val_loss: 0.6141 - val_accuracy: 0.7854\n",
      "Epoch 310/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8653 - val_loss: 0.5997 - val_accuracy: 0.7732\n",
      "Epoch 311/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3088 - accuracy: 0.8733 - val_loss: 0.6078 - val_accuracy: 0.7927\n",
      "Epoch 312/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8761 - val_loss: 0.6139 - val_accuracy: 0.7780\n",
      "Epoch 313/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3139 - accuracy: 0.8721 - val_loss: 0.6151 - val_accuracy: 0.7805\n",
      "Epoch 314/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8698 - val_loss: 0.6117 - val_accuracy: 0.7902\n",
      "Epoch 315/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8607 - val_loss: 0.6212 - val_accuracy: 0.8049\n",
      "Epoch 316/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3155 - accuracy: 0.8784 - val_loss: 0.5612 - val_accuracy: 0.8220\n",
      "Epoch 317/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8721 - val_loss: 0.6156 - val_accuracy: 0.7854\n",
      "Epoch 318/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8767 - val_loss: 0.6049 - val_accuracy: 0.7927\n",
      "Epoch 319/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.8784 - val_loss: 0.6367 - val_accuracy: 0.7927\n",
      "Epoch 320/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8727 - val_loss: 0.6091 - val_accuracy: 0.8024\n",
      "Epoch 321/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8733 - val_loss: 0.6002 - val_accuracy: 0.7927\n",
      "Epoch 322/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2977 - accuracy: 0.8825 - val_loss: 0.6082 - val_accuracy: 0.7976\n",
      "Epoch 323/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3025 - accuracy: 0.8756 - val_loss: 0.6579 - val_accuracy: 0.7659\n",
      "Epoch 324/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8802 - val_loss: 0.6442 - val_accuracy: 0.7927\n",
      "Epoch 325/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8773 - val_loss: 0.6076 - val_accuracy: 0.7951\n",
      "Epoch 326/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3022 - accuracy: 0.8842 - val_loss: 0.6714 - val_accuracy: 0.7634\n",
      "Epoch 327/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8842 - val_loss: 0.6164 - val_accuracy: 0.7902\n",
      "Epoch 328/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8813 - val_loss: 0.5882 - val_accuracy: 0.7902\n",
      "Epoch 329/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8876 - val_loss: 0.5565 - val_accuracy: 0.7951\n",
      "Epoch 330/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.8767 - val_loss: 0.5778 - val_accuracy: 0.8024\n",
      "Epoch 331/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8784 - val_loss: 0.5939 - val_accuracy: 0.8220\n",
      "Epoch 332/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2938 - accuracy: 0.8836 - val_loss: 0.5880 - val_accuracy: 0.8024\n",
      "Epoch 333/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.3135 - accuracy: 0.8744 - val_loss: 0.6608 - val_accuracy: 0.7707\n",
      "Epoch 334/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8842 - val_loss: 0.6122 - val_accuracy: 0.7854\n",
      "Epoch 335/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 0.8698 - val_loss: 0.6284 - val_accuracy: 0.7976\n",
      "Epoch 336/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8819 - val_loss: 0.6265 - val_accuracy: 0.7976\n",
      "Epoch 337/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3040 - accuracy: 0.8761 - val_loss: 0.6172 - val_accuracy: 0.8024\n",
      "Epoch 338/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.8807 - val_loss: 0.5952 - val_accuracy: 0.8024\n",
      "Epoch 339/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.8796 - val_loss: 0.6136 - val_accuracy: 0.8073\n",
      "Epoch 340/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8756 - val_loss: 0.6009 - val_accuracy: 0.7976\n",
      "Epoch 341/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8790 - val_loss: 0.5773 - val_accuracy: 0.8146\n",
      "Epoch 342/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.8870 - val_loss: 0.6292 - val_accuracy: 0.7902\n",
      "Epoch 343/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8796 - val_loss: 0.5767 - val_accuracy: 0.7976\n",
      "Epoch 344/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2972 - accuracy: 0.8825 - val_loss: 0.6217 - val_accuracy: 0.8049\n",
      "Epoch 345/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8945 - val_loss: 0.6191 - val_accuracy: 0.7829\n",
      "Epoch 346/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8750 - val_loss: 0.6136 - val_accuracy: 0.7976\n",
      "Epoch 347/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8933 - val_loss: 0.6019 - val_accuracy: 0.7829\n",
      "Epoch 348/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2871 - accuracy: 0.8876 - val_loss: 0.6724 - val_accuracy: 0.7878\n",
      "Epoch 349/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.8830 - val_loss: 0.6260 - val_accuracy: 0.8049\n",
      "Epoch 350/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8928 - val_loss: 0.6353 - val_accuracy: 0.7878\n",
      "Epoch 351/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2943 - accuracy: 0.8756 - val_loss: 0.6062 - val_accuracy: 0.8049\n",
      "Epoch 352/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8750 - val_loss: 0.6599 - val_accuracy: 0.7707\n",
      "Epoch 353/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8842 - val_loss: 0.6094 - val_accuracy: 0.8049\n",
      "Epoch 354/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2847 - accuracy: 0.9014 - val_loss: 0.6272 - val_accuracy: 0.7976\n",
      "Epoch 355/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8693 - val_loss: 0.5876 - val_accuracy: 0.8220\n",
      "Epoch 356/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8847 - val_loss: 0.6055 - val_accuracy: 0.8073\n",
      "Epoch 357/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.8882 - val_loss: 0.6068 - val_accuracy: 0.8024\n",
      "Epoch 358/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8911 - val_loss: 0.6104 - val_accuracy: 0.8122\n",
      "Epoch 359/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.8899 - val_loss: 0.6086 - val_accuracy: 0.8073\n",
      "Epoch 360/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.8888 - val_loss: 0.6522 - val_accuracy: 0.7878\n",
      "Epoch 361/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8956 - val_loss: 0.5980 - val_accuracy: 0.8024\n",
      "Epoch 362/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8911 - val_loss: 0.6113 - val_accuracy: 0.8146\n",
      "Epoch 363/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.8870 - val_loss: 0.6685 - val_accuracy: 0.8122\n",
      "Epoch 364/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.8865 - val_loss: 0.6038 - val_accuracy: 0.8146\n",
      "Epoch 365/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8825 - val_loss: 0.6629 - val_accuracy: 0.7878\n",
      "Epoch 366/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8813 - val_loss: 0.6365 - val_accuracy: 0.7610\n",
      "Epoch 367/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2850 - accuracy: 0.8865 - val_loss: 0.6134 - val_accuracy: 0.8024\n",
      "Epoch 368/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8922 - val_loss: 0.6025 - val_accuracy: 0.8098\n",
      "Epoch 369/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.8939 - val_loss: 0.6510 - val_accuracy: 0.7756\n",
      "Epoch 370/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.8779 - val_loss: 0.6328 - val_accuracy: 0.7976\n",
      "Epoch 371/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2698 - accuracy: 0.8933 - val_loss: 0.6162 - val_accuracy: 0.8073\n",
      "Epoch 372/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8893 - val_loss: 0.6570 - val_accuracy: 0.7902\n",
      "Epoch 373/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8893 - val_loss: 0.6164 - val_accuracy: 0.8000\n",
      "Epoch 374/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.8899 - val_loss: 0.6250 - val_accuracy: 0.7902\n",
      "Epoch 375/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.8876 - val_loss: 0.5957 - val_accuracy: 0.7951\n",
      "Epoch 376/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8916 - val_loss: 0.6031 - val_accuracy: 0.8073\n",
      "Epoch 377/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.8997 - val_loss: 0.6584 - val_accuracy: 0.8024\n",
      "Epoch 378/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2636 - accuracy: 0.8928 - val_loss: 0.6255 - val_accuracy: 0.8098\n",
      "Epoch 379/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8911 - val_loss: 0.5918 - val_accuracy: 0.8171\n",
      "Epoch 380/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.8974 - val_loss: 0.6114 - val_accuracy: 0.8268\n",
      "Epoch 381/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.8859 - val_loss: 0.6223 - val_accuracy: 0.7902\n",
      "Epoch 382/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2859 - accuracy: 0.8893 - val_loss: 0.6497 - val_accuracy: 0.8049\n",
      "Epoch 383/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8893 - val_loss: 0.6252 - val_accuracy: 0.8049\n",
      "Epoch 384/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.8979 - val_loss: 0.6122 - val_accuracy: 0.8024\n",
      "Epoch 385/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8893 - val_loss: 0.6185 - val_accuracy: 0.7976\n",
      "Epoch 386/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.8911 - val_loss: 0.6173 - val_accuracy: 0.8098\n",
      "Epoch 387/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8865 - val_loss: 0.6309 - val_accuracy: 0.8098\n",
      "Epoch 388/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.9048 - val_loss: 0.5918 - val_accuracy: 0.8146\n",
      "Epoch 389/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.8985 - val_loss: 0.6147 - val_accuracy: 0.8244\n",
      "Epoch 390/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8819 - val_loss: 0.6510 - val_accuracy: 0.7878\n",
      "Epoch 391/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2828 - accuracy: 0.8876 - val_loss: 0.6021 - val_accuracy: 0.8024\n",
      "Epoch 392/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.8870 - val_loss: 0.6358 - val_accuracy: 0.8049\n",
      "Epoch 393/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2637 - accuracy: 0.9019 - val_loss: 0.6399 - val_accuracy: 0.8220\n",
      "Epoch 394/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.8968 - val_loss: 0.6272 - val_accuracy: 0.8195\n",
      "Epoch 395/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 0.9002 - val_loss: 0.6209 - val_accuracy: 0.8415\n",
      "Epoch 396/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2679 - accuracy: 0.8968 - val_loss: 0.6036 - val_accuracy: 0.8122\n",
      "Epoch 397/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.9025 - val_loss: 0.6016 - val_accuracy: 0.8244\n",
      "Epoch 398/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.9077 - val_loss: 0.5637 - val_accuracy: 0.8293\n",
      "Epoch 399/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8922 - val_loss: 0.5910 - val_accuracy: 0.8220\n",
      "Epoch 400/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8945 - val_loss: 0.6390 - val_accuracy: 0.8146\n",
      "Epoch 401/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.8928 - val_loss: 0.6094 - val_accuracy: 0.8171\n",
      "Epoch 402/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.8968 - val_loss: 0.6028 - val_accuracy: 0.8293\n",
      "Epoch 403/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.9002 - val_loss: 0.5983 - val_accuracy: 0.8317\n",
      "Epoch 404/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2570 - accuracy: 0.9008 - val_loss: 0.5946 - val_accuracy: 0.8244\n",
      "Epoch 405/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9002 - val_loss: 0.6170 - val_accuracy: 0.8171\n",
      "Epoch 406/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8985 - val_loss: 0.6330 - val_accuracy: 0.8098\n",
      "Epoch 407/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.8956 - val_loss: 0.6013 - val_accuracy: 0.8146\n",
      "Epoch 408/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9077 - val_loss: 0.5983 - val_accuracy: 0.8244\n",
      "Epoch 409/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.9025 - val_loss: 0.5992 - val_accuracy: 0.8463\n",
      "Epoch 410/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2526 - accuracy: 0.8997 - val_loss: 0.5771 - val_accuracy: 0.8171\n",
      "Epoch 411/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2437 - accuracy: 0.9088 - val_loss: 0.6553 - val_accuracy: 0.8171\n",
      "Epoch 412/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8985 - val_loss: 0.5729 - val_accuracy: 0.8244\n",
      "Epoch 413/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.8922 - val_loss: 0.6005 - val_accuracy: 0.8122\n",
      "Epoch 414/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.9002 - val_loss: 0.6005 - val_accuracy: 0.7976\n",
      "Epoch 415/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2697 - accuracy: 0.8939 - val_loss: 0.5921 - val_accuracy: 0.8439\n",
      "Epoch 416/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.8968 - val_loss: 0.5894 - val_accuracy: 0.8317\n",
      "Epoch 417/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2530 - accuracy: 0.9077 - val_loss: 0.5961 - val_accuracy: 0.7829\n",
      "Epoch 418/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.9054 - val_loss: 0.6119 - val_accuracy: 0.8171\n",
      "Epoch 419/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.9065 - val_loss: 0.5865 - val_accuracy: 0.8244\n",
      "Epoch 420/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9088 - val_loss: 0.6579 - val_accuracy: 0.8293\n",
      "Epoch 421/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2606 - accuracy: 0.9048 - val_loss: 0.6204 - val_accuracy: 0.8268\n",
      "Epoch 422/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9054 - val_loss: 0.6324 - val_accuracy: 0.8098\n",
      "Epoch 423/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.9077 - val_loss: 0.6158 - val_accuracy: 0.8049\n",
      "Epoch 424/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.9048 - val_loss: 0.6320 - val_accuracy: 0.8122\n",
      "Epoch 425/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.9008 - val_loss: 0.5949 - val_accuracy: 0.8293\n",
      "Epoch 426/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8985 - val_loss: 0.6067 - val_accuracy: 0.8390\n",
      "Epoch 427/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2551 - accuracy: 0.8997 - val_loss: 0.6604 - val_accuracy: 0.8220\n",
      "Epoch 428/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2697 - accuracy: 0.8991 - val_loss: 0.6680 - val_accuracy: 0.8000\n",
      "Epoch 429/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8911 - val_loss: 0.5546 - val_accuracy: 0.8268\n",
      "Epoch 430/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.8922 - val_loss: 0.6040 - val_accuracy: 0.8463\n",
      "Epoch 431/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.9054 - val_loss: 0.5836 - val_accuracy: 0.8463\n",
      "Epoch 432/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2437 - accuracy: 0.9037 - val_loss: 0.5798 - val_accuracy: 0.8098\n",
      "Epoch 433/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9037 - val_loss: 0.6216 - val_accuracy: 0.8098\n",
      "Epoch 434/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.9065 - val_loss: 0.6324 - val_accuracy: 0.7951\n",
      "Epoch 435/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.8951 - val_loss: 0.5991 - val_accuracy: 0.8268\n",
      "Epoch 436/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.9083 - val_loss: 0.6121 - val_accuracy: 0.8195\n",
      "Epoch 437/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.9042 - val_loss: 0.6182 - val_accuracy: 0.8341\n",
      "Epoch 438/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9014 - val_loss: 0.5996 - val_accuracy: 0.8171\n",
      "Epoch 439/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2494 - accuracy: 0.9140 - val_loss: 0.6173 - val_accuracy: 0.7927\n",
      "Epoch 440/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2490 - accuracy: 0.9071 - val_loss: 0.5783 - val_accuracy: 0.8293\n",
      "Epoch 441/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.9100 - val_loss: 0.6184 - val_accuracy: 0.8195\n",
      "Epoch 442/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9169 - val_loss: 0.5991 - val_accuracy: 0.8244\n",
      "Epoch 443/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9014 - val_loss: 0.6322 - val_accuracy: 0.8317\n",
      "Epoch 444/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.9128 - val_loss: 0.6046 - val_accuracy: 0.8244\n",
      "Epoch 445/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2324 - accuracy: 0.9106 - val_loss: 0.6682 - val_accuracy: 0.8024\n",
      "Epoch 446/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.9065 - val_loss: 0.6103 - val_accuracy: 0.8317\n",
      "Epoch 447/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2400 - accuracy: 0.9071 - val_loss: 0.6878 - val_accuracy: 0.8146\n",
      "Epoch 448/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.9163 - val_loss: 0.5876 - val_accuracy: 0.8415\n",
      "Epoch 449/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.9065 - val_loss: 0.6716 - val_accuracy: 0.8220\n",
      "Epoch 450/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2637 - accuracy: 0.8928 - val_loss: 0.6119 - val_accuracy: 0.8293\n",
      "Epoch 451/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.9025 - val_loss: 0.6189 - val_accuracy: 0.8268\n",
      "Epoch 452/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.8997 - val_loss: 0.6625 - val_accuracy: 0.8341\n",
      "Epoch 453/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.9014 - val_loss: 0.6128 - val_accuracy: 0.8537\n",
      "Epoch 454/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.9111 - val_loss: 0.6349 - val_accuracy: 0.8171\n",
      "Epoch 455/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.9002 - val_loss: 0.6330 - val_accuracy: 0.8220\n",
      "Epoch 456/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9111 - val_loss: 0.6610 - val_accuracy: 0.8244\n",
      "Epoch 457/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2508 - accuracy: 0.9048 - val_loss: 0.6416 - val_accuracy: 0.8317\n",
      "Epoch 458/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2472 - accuracy: 0.9083 - val_loss: 0.5960 - val_accuracy: 0.8390\n",
      "Epoch 459/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2291 - accuracy: 0.9157 - val_loss: 0.5921 - val_accuracy: 0.8561\n",
      "Epoch 460/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9060 - val_loss: 0.6406 - val_accuracy: 0.8195\n",
      "Epoch 461/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.9037 - val_loss: 0.6689 - val_accuracy: 0.8195\n",
      "Epoch 462/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.9146 - val_loss: 0.6733 - val_accuracy: 0.8390\n",
      "Epoch 463/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.8991 - val_loss: 0.6812 - val_accuracy: 0.8293\n",
      "Epoch 464/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9106 - val_loss: 0.6863 - val_accuracy: 0.8098\n",
      "Epoch 465/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9065 - val_loss: 0.6391 - val_accuracy: 0.8244\n",
      "Epoch 466/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2422 - accuracy: 0.9065 - val_loss: 0.6331 - val_accuracy: 0.8293\n",
      "Epoch 467/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.9060 - val_loss: 0.6932 - val_accuracy: 0.8244\n",
      "Epoch 468/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.9117 - val_loss: 0.5890 - val_accuracy: 0.8488\n",
      "Epoch 469/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.9071 - val_loss: 0.6359 - val_accuracy: 0.8049\n",
      "Epoch 470/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 0.9169 - val_loss: 0.6052 - val_accuracy: 0.8439\n",
      "Epoch 471/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2404 - accuracy: 0.9111 - val_loss: 0.6320 - val_accuracy: 0.8293\n",
      "Epoch 472/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9111 - val_loss: 0.6225 - val_accuracy: 0.8415\n",
      "Epoch 473/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.9111 - val_loss: 0.5986 - val_accuracy: 0.8244\n",
      "Epoch 474/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9220 - val_loss: 0.6290 - val_accuracy: 0.8293\n",
      "Epoch 475/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.9048 - val_loss: 0.6658 - val_accuracy: 0.8268\n",
      "Epoch 476/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9128 - val_loss: 0.6565 - val_accuracy: 0.8220\n",
      "Epoch 477/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.9071 - val_loss: 0.6543 - val_accuracy: 0.8366\n",
      "Epoch 478/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9260 - val_loss: 0.6287 - val_accuracy: 0.8146\n",
      "Epoch 479/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9174 - val_loss: 0.6684 - val_accuracy: 0.8268\n",
      "Epoch 480/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9180 - val_loss: 0.6226 - val_accuracy: 0.8268\n",
      "Epoch 481/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2282 - accuracy: 0.9146 - val_loss: 0.6329 - val_accuracy: 0.8098\n",
      "Epoch 482/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9111 - val_loss: 0.6083 - val_accuracy: 0.8439\n",
      "Epoch 483/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9163 - val_loss: 0.6336 - val_accuracy: 0.8244\n",
      "Epoch 484/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2224 - accuracy: 0.9140 - val_loss: 0.5946 - val_accuracy: 0.8415\n",
      "Epoch 485/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9140 - val_loss: 0.6151 - val_accuracy: 0.8390\n",
      "Epoch 486/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9220 - val_loss: 0.6338 - val_accuracy: 0.8512\n",
      "Epoch 487/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9249 - val_loss: 0.6321 - val_accuracy: 0.8415\n",
      "Epoch 488/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9134 - val_loss: 0.6945 - val_accuracy: 0.8024\n",
      "Epoch 489/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9203 - val_loss: 0.6200 - val_accuracy: 0.8341\n",
      "Epoch 490/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.9065 - val_loss: 0.6513 - val_accuracy: 0.8293\n",
      "Epoch 491/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2191 - accuracy: 0.9192 - val_loss: 0.6763 - val_accuracy: 0.8244\n",
      "Epoch 492/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2290 - accuracy: 0.9186 - val_loss: 0.6690 - val_accuracy: 0.8341\n",
      "Epoch 493/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.9048 - val_loss: 0.6491 - val_accuracy: 0.8561\n",
      "Epoch 494/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.9048 - val_loss: 0.6378 - val_accuracy: 0.8537\n",
      "Epoch 495/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9203 - val_loss: 0.6367 - val_accuracy: 0.8537\n",
      "Epoch 496/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9243 - val_loss: 0.7272 - val_accuracy: 0.8244\n",
      "Epoch 497/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2197 - accuracy: 0.9186 - val_loss: 0.6532 - val_accuracy: 0.8317\n",
      "Epoch 498/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.9083 - val_loss: 0.6341 - val_accuracy: 0.8244\n",
      "Epoch 499/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.9123 - val_loss: 0.6944 - val_accuracy: 0.8024\n",
      "Epoch 500/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.9128 - val_loss: 0.6311 - val_accuracy: 0.8561\n",
      "Epoch 501/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2256 - accuracy: 0.9203 - val_loss: 0.6076 - val_accuracy: 0.8537\n",
      "Epoch 502/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2232 - accuracy: 0.9146 - val_loss: 0.6253 - val_accuracy: 0.8488\n",
      "Epoch 503/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.9111 - val_loss: 0.6640 - val_accuracy: 0.8268\n",
      "Epoch 504/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.9088 - val_loss: 0.6639 - val_accuracy: 0.8341\n",
      "Epoch 505/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 0.9214 - val_loss: 0.6610 - val_accuracy: 0.8268\n",
      "Epoch 506/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9163 - val_loss: 0.6761 - val_accuracy: 0.8341\n",
      "Epoch 507/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 0.9260 - val_loss: 0.6593 - val_accuracy: 0.8268\n",
      "Epoch 508/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9174 - val_loss: 0.6343 - val_accuracy: 0.8366\n",
      "Epoch 509/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2391 - accuracy: 0.9100 - val_loss: 0.7347 - val_accuracy: 0.8341\n",
      "Epoch 510/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2170 - accuracy: 0.9237 - val_loss: 0.6628 - val_accuracy: 0.8341\n",
      "Epoch 511/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9151 - val_loss: 0.6410 - val_accuracy: 0.8073\n",
      "Epoch 512/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2422 - accuracy: 0.9048 - val_loss: 0.6562 - val_accuracy: 0.8341\n",
      "Epoch 513/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9192 - val_loss: 0.6584 - val_accuracy: 0.8439\n",
      "Epoch 514/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9197 - val_loss: 0.6824 - val_accuracy: 0.8244\n",
      "Epoch 515/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9214 - val_loss: 0.6280 - val_accuracy: 0.8293\n",
      "Epoch 516/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2371 - accuracy: 0.9106 - val_loss: 0.6713 - val_accuracy: 0.8415\n",
      "Epoch 517/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2233 - accuracy: 0.9220 - val_loss: 0.7263 - val_accuracy: 0.8244\n",
      "Epoch 518/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2406 - accuracy: 0.9151 - val_loss: 0.6768 - val_accuracy: 0.8317\n",
      "Epoch 519/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9169 - val_loss: 0.6463 - val_accuracy: 0.8488\n",
      "Epoch 520/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9083 - val_loss: 0.6629 - val_accuracy: 0.8244\n",
      "Epoch 521/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9157 - val_loss: 0.6524 - val_accuracy: 0.8512\n",
      "Epoch 522/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9151 - val_loss: 0.6062 - val_accuracy: 0.8415\n",
      "Epoch 523/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.9220 - val_loss: 0.6353 - val_accuracy: 0.8488\n",
      "Epoch 524/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9134 - val_loss: 0.6205 - val_accuracy: 0.8463\n",
      "Epoch 525/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9203 - val_loss: 0.5821 - val_accuracy: 0.8488\n",
      "Epoch 526/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9140 - val_loss: 0.6319 - val_accuracy: 0.8171\n",
      "Epoch 527/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2290 - accuracy: 0.9186 - val_loss: 0.6254 - val_accuracy: 0.8390\n",
      "Epoch 528/555\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2152 - accuracy: 0.9266 - val_loss: 0.6200 - val_accuracy: 0.8463\n",
      "Epoch 529/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2157 - accuracy: 0.9226 - val_loss: 0.6208 - val_accuracy: 0.8537\n",
      "Epoch 530/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9117 - val_loss: 0.6597 - val_accuracy: 0.8610\n",
      "Epoch 531/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.8979 - val_loss: 0.6551 - val_accuracy: 0.8268\n",
      "Epoch 532/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9220 - val_loss: 0.6747 - val_accuracy: 0.8293\n",
      "Epoch 533/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9146 - val_loss: 0.6578 - val_accuracy: 0.8390\n",
      "Epoch 534/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9128 - val_loss: 0.6706 - val_accuracy: 0.8293\n",
      "Epoch 535/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9249 - val_loss: 0.6765 - val_accuracy: 0.8488\n",
      "Epoch 536/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9255 - val_loss: 0.6082 - val_accuracy: 0.8537\n",
      "Epoch 537/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9174 - val_loss: 0.6234 - val_accuracy: 0.8463\n",
      "Epoch 538/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2207 - accuracy: 0.9192 - val_loss: 0.6754 - val_accuracy: 0.8244\n",
      "Epoch 539/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2542 - accuracy: 0.9019 - val_loss: 0.6981 - val_accuracy: 0.8000\n",
      "Epoch 540/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9174 - val_loss: 0.6243 - val_accuracy: 0.8585\n",
      "Epoch 541/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2162 - accuracy: 0.9226 - val_loss: 0.6453 - val_accuracy: 0.8463\n",
      "Epoch 542/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9237 - val_loss: 0.6390 - val_accuracy: 0.8585\n",
      "Epoch 543/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9232 - val_loss: 0.6208 - val_accuracy: 0.8415\n",
      "Epoch 544/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2074 - accuracy: 0.9237 - val_loss: 0.5923 - val_accuracy: 0.8561\n",
      "Epoch 545/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9243 - val_loss: 0.6405 - val_accuracy: 0.8512\n",
      "Epoch 546/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.9180 - val_loss: 0.6415 - val_accuracy: 0.8488\n",
      "Epoch 547/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9111 - val_loss: 0.5992 - val_accuracy: 0.8488\n",
      "Epoch 548/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9266 - val_loss: 0.6300 - val_accuracy: 0.8341\n",
      "Epoch 549/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2158 - accuracy: 0.9226 - val_loss: 0.6123 - val_accuracy: 0.8537\n",
      "Epoch 550/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9323 - val_loss: 0.6022 - val_accuracy: 0.8537\n",
      "Epoch 551/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9266 - val_loss: 0.6637 - val_accuracy: 0.8561\n",
      "Epoch 552/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9203 - val_loss: 0.7065 - val_accuracy: 0.8317\n",
      "Epoch 553/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9220 - val_loss: 0.7225 - val_accuracy: 0.8220\n",
      "Epoch 554/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9209 - val_loss: 0.6586 - val_accuracy: 0.8463\n",
      "Epoch 555/555\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9266 - val_loss: 0.6417 - val_accuracy: 0.8390\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_res, y_train_enc, validation_data=(X_test, y_test_enc), batch_size=32,epochs=555, callbacks=[callback])\n",
    "# history = model.fit(X_train_res, y_train_enc, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, train_acc = model.evaluate(X_train_res, y_train_enc, verbose=0)\n",
    "# _, test_acc = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17d538b84f0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17d54c2d9a0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy during training\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "# plt.xlim(0,400)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot accuracy during training\n",
    "# plt.subplot(212)\n",
    "# plt.title('Accuracy')\n",
    "# plt.plot(history.history['accuracy'], label='train')\n",
    "# # plt.plot(history.history['val_accuracy'], label='test')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_enc = pd.get_dummies(y_pred)\n",
    "y_test_enc = pd.get_dummies(y_test_enc)\n",
    "\n",
    "y_test_value, y_pred_value = y_test_enc.values.argmax(axis=1), y_pred_enc.values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8390243902439024\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_value, y_pred_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_pred_enc = pd.get_dummies(y_pred)\n",
    "# # y_test_enc = pd.get_dummies(y_test)\n",
    "\n",
    "# y_test_value, y_pred_value = y_test.values.argmax(axis=1), y_pred.values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax - relu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relu - softmax\n",
    "- test 2 = 0.5658536585365853 (dense1 50 epoch 100)\n",
    "- test 3 = 0.5954325436457234 (dense1 50 epoch 200)\n",
    "-\n",
    "- ALL GLCM + Fusi\n",
    "- test 4 = 0.6585365853658537 (dense2 32 64 epoch 50)\n",
    "- test 5 = 0.6682926829268293 (dense2 32 64 epoch 100)\n",
    "- test 6 = 0.675609756097561 (dense2 32 64 epoch 200)\n",
    "- test 7 = 0.6829268292682927 (dense2 32 64 epoch 300)\n",
    "- test 8 = 0.6685352342423534 (dense2 32 128 epoch 50)\n",
    "- test 9 = 0.6780487804878049 (dense2 32 128 epoch 500)\n",
    "- test 10 = 0.6878048780487804 (dense2 32 128 epoch 1000)\n",
    "-\n",
    "- fusi\n",
    "- test 11 = 0.697560975609756 (dense 3 64 128 256 epoch 750)\n",
    "- test 12 = 0.665 (dense 3 32 64 128 epoch 750)\n",
    "- \n",
    "- warna \n",
    "- Fusi (glcm+)\n",
    "- dense 1\n",
    "- 0.6804878048780488 (dense1 50 epoch 100)\n",
    "- 0.7268292682926829 (dense1 50 epoch 250)\n",
    "- 0.7097560975609756 (dense1 50 epoch 500)\n",
    "- 0.7317073170731707 (dense1 50 epoch 750)\n",
    "- 0.7048780487804878 (dense1 50 epoch 1000)\n",
    "- \n",
    "- 0.7146341463414634 (dense1 100 epoch 100)\n",
    "- 0.7048780487804878 (dense1 100 epoch 250)\n",
    "- 0.7390243902439024 (dense1 100 epoch 500)\n",
    "- 0.7414634146341463 (dense1 100 epoch 750)\n",
    "- 0.7317073170731707 (dense1 100 epoch 1000)\n",
    "-\n",
    "- 0.697560975609756 (dense1 150 epoch 100)\n",
    "- 0.7073170731707317 (dense1 150 epoch 250)\n",
    "- 0.7365853658536585 (dense1 150 epoch 500)\n",
    "- 0.7341463414634146 (dense1 150 epoch 750)\n",
    "- 0.7536585365853659 (dense1 150 epoch 1000)\n",
    "- \n",
    "- dense 2\n",
    "- 0.7146341463414634 (dense2 32 64 epoch 100)\n",
    "- 0.7536585365853659 (dense2 32 64 epoch 250)\n",
    "- 0.7292682926829268 (dense2 32 64 epoch 500)\n",
    "- 0.7536585365853659 (dense2 32 64 epoch 750)\n",
    "- \n",
    "- dense 3 \n",
    "- test 1 = 0.7365853658536585 (dense3 32 64 128 epoch 300)\n",
    "- test 2 = 0.7609756097560976 (dense3 32 64 128 epoch 500)\n",
    "- test 3 = 0.7926829268292683 (dense3 32 64 128 epoch 600)\n",
    "- test 4 = 0.8146341463414634 (dense3 32 64 128 epoch 750)\n",
    "- test 5 = 0.7902439024390244 (dense3 32 64 128 epoch 900)\n",
    "- \n",
    "- Only fusi\n",
    "- test 1 = 0.674556724455646 (dense3 32 64 128 epoch 100)\n",
    "- test 2 = 0.697560975609756 (dense3 32 64 128 epoch 300)\n",
    "- test 3 = 0.7097560975609756 (Dense3 32 64 128 epoch 500)\n",
    "- test 9 = 0.7308292682926829 (Dense3 32 64 128 epoch 750)\n",
    "- test 4 = 0.7536585365853659 (Dense3 32 64 128 epoch 1000)\n",
    "-\n",
    "- test 5 = 0.751219512195122 (Dense3 64 128 256 epoch 300)\n",
    "- test 10 = 0.8146341463414634 (Dense3 64 128 256 epoch 420 earlystop patience 25)\n",
    "- test 11 = 0.8414634146341463 (Dense3 64 128 256 epoch 555 earlystop patience 30)\n",
    "- test 6 = 0.7731707317073171 (Dense3 64 128 256 epoch 600)\n",
    "- test 7 = 0.7780487804878049 (Dense3 64 128 256 epoch 750)\n",
    "- test 8 = 0.7926829268292683 (Dense3 64 128 256 epoch 1000)\n",
    "- \n",
    "\n",
    "-\n",
    "- minmax scaling -1, 1\n",
    "- test1 =  (Dense 3 64 128 256 epoch 600)\n",
    "-\n",
    "64 128 256 epoch 550\n",
    "Accuracy: 0.839024\n",
    "Precision: 0.840000\n",
    "Recall: 0.839024\n",
    "F1 Score: 0.838963\n",
    "array([[168,  24],\n",
    "       [ 42, 176]], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       192\n",
      "           1       0.88      0.81      0.84       218\n",
      "\n",
      "    accuracy                           0.84       410\n",
      "   macro avg       0.84      0.84      0.84       410\n",
      "weighted avg       0.84      0.84      0.84       410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_value, y_pred_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_classes = y_pred[:,0]\n",
    "# y_pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.839024\n",
      "Precision: 0.840000\n",
      "Recall: 0.839024\n",
      "F1 Score: 0.838963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[168,  24],\n",
       "       [ 42, 176]], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # confusion matrix\n",
    "# confusion = confusion_matrix(y_test_enc.values.argmax(axis=1), y_pred_enc.values.argmax(axis=1))\n",
    "# # print(confusion)\n",
    "\n",
    "# TP = confusion[0][0]\n",
    "# FP = confusion[0][1]\n",
    "# FN = confusion[1][0]\n",
    "# TN = confusion[1][1]\n",
    "\n",
    "# Method 1: Sklearn\n",
    "accuracy = accuracy_score(y_test_value, y_pred_value)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "precision = precision_score(y_test_value, y_pred_value, average='macro')\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "recall = recall_score(y_test_value, y_pred_value, average='micro')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "f1 = f1_score(y_test_value, y_pred_value, average='macro')\n",
    "print('F1 Score: %f' % f1)\n",
    "\n",
    "c_matrix = confusion_matrix(y_test_value, y_pred_value)\n",
    "c_matrix\n",
    "\n",
    "# # Method 2: Manual\n",
    "\n",
    "# # Confusion matrix:\n",
    "# # [[TP,FP],\n",
    "# #  [FN,TN]] -> TP = True Positive, FP = False Positive, FN = False Negative, TN = True Negative\n",
    "\n",
    "\n",
    "# # Accuracy/Akurasi\n",
    "# akurasi = (TN + TP) / (TP+FP+FN+TN)\n",
    "\n",
    "# # Precision/Presisi -> Menghitung positive predictive value\n",
    "# presisi = TP/(TP+FP)\n",
    "\n",
    "# # Recall -> Recall is also known as sensitivity or true positive rate\n",
    "# recall = TP/(TP+FN)\n",
    "\n",
    "# error_rate = (FN + FP) / (TP+FP+FN+TN)\n",
    "\n",
    "# print(\"Akurasi: \",akurasi)\n",
    "# print(\"Presisi: \",presisi)\n",
    "# print(\"Recall: \",recall)\n",
    "# print(\"Error Rate: \",error_rate)\n",
    "\n",
    "# confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # model.save_weights(\"./U2Net/tsmodelweight.h5\")\n",
    "# model.save(\"./U2Net/StdScMulticlass555Warna.h5\")\n",
    "\n",
    "# # model.save(\"./U2Net/tsmodel.h5\")\n",
    "# # model_name = \"jobmodel.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pickle import dump\n",
    "# dump(StdScaler, open('./U2Net/StdScScaler555Warna.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # model = keras.Sequential([\n",
    "# #     keras.layers.Flatten(input_shape=(16, )),\n",
    "# #     keras.layers.Dense(500, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "# #     keras.layers.Dropout(rate=0.1),\n",
    "# #     keras.layers.Dense(2, activation='relu'),\n",
    "# # ])\n",
    "\n",
    "# model = keras.Sequential()\n",
    "# # Adding the input layer and the first hidden layer\n",
    "# model.add(Dense(80, kernel_initializer='uniform', activation='relu', input_dim=20, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "# # Adding dropouto prevent overfitting\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# # Adding the output layer\n",
    "# model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# adam = keras.optimizers.Adam(0.1)\n",
    "# model.compile(optimizer=adam,\n",
    "#               loss='BinaryCrossentropy',\n",
    "#               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # history = model.fit(X_train, y_train, epochs=500, batch_size=32, validation_data=(X_val, y_val))\n",
    "# history = model.fit(X_train, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_train = history.history['loss']\n",
    "# # loss_val = history.history['val_loss']\n",
    "# epochs = range(0,100)\n",
    "# plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "# # plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "# plt.title('Training and Validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_train = history.history['accuracy']\n",
    "# # loss_val = history.history['val_accuracy']\n",
    "# epochs = range(0,100)\n",
    "# plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "# # plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "# plt.title('Training and Validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
